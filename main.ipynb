{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt  # Biblioteca para gerar gráficos\n",
    "import pandas as pd\n",
    "from sklearn import metrics, model_selection\n",
    "from scipy import stats\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('breastcancer.csv', delimiter=',')\n",
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere o conjunto de dados disponível em `breastcancer.csv`, organizado\n",
    "em 31 colunas, sendo as 30 primeiras colunas os atributos e a última coluna a\n",
    "saída. Os 30 atributos coletados de exames médicos são usados no diagnóstico\n",
    "do câncer de mama, sendo 1 a classe positiva e 0 a classe negativa. Maiores \n",
    "detalhes sobre os dados podem ser conferidos em \n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Considerando uma validação cruzada em 10 folds, avalie modelos de classicação binária nos dados em questão. Para tanto, use as abordagens abaixo:\n",
    "- Regressão logística (treinado com GD ou SGD);\n",
    "- Análise do discriminante Gaussiano;\n",
    "- Naive Bayes Gaussiano;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Set:\n",
    "    def __init__(self, dataset, features, output):\n",
    "        self.dataset = dataset\n",
    "        self.features = features\n",
    "        self.output = output\n",
    "\n",
    "    def get_n(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "    def get_x(self):\n",
    "        return self.dataset[:, self.features]\n",
    "    \n",
    "    def get_x_apply(self, func):\n",
    "        return func(self.dataset[:, self.features])\n",
    "\n",
    "    def set_x(self, new_x):\n",
    "        self.x = new_x\n",
    "\n",
    "    def get_y(self):\n",
    "        return self.dataset[:, self.output]\n",
    "\n",
    "    def get_X(self, normal_fun=None):\n",
    "        if (normal_fun):\n",
    "            return np.c_[np.ones(self.get_n()), normal_fun(self.get_x())]\n",
    "        else:\n",
    "            return np.c_[np.ones(self.get_n()), self.get_x()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_split(array, k = int):\n",
    "    \"\"\"realiza o split dos dados em k-folds\"\"\"\n",
    "    shuffled_data = np.random.permutation(array)\n",
    "    folds = np.array_split(shuffled_data, k)\n",
    "    return folds\n",
    "\n",
    "def k_fold_train_test(folds):\n",
    "    \"\"\"retorna um vetor com as configurações de treino e teste definidas pelo k-fold split\"\"\"\n",
    "    results = []\n",
    "    for i, fold in enumerate(folds):\n",
    "        train = np.vstack([x for j, x in enumerate(folds) if j != i])\n",
    "        test = fold\n",
    "        results.append((i, train, test))\n",
    "    return results\n",
    "    \n",
    "\n",
    "folds = k_fold_split(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "def GD(X, y, learning_rate, epochs):\n",
    "    # inicia valores\n",
    "    n = y.shape[0]\n",
    "    # w = np.random.randn(X.shape[1])\n",
    "    w = np.zeros(X.shape[1])\n",
    "\n",
    "    # atualiza pesos (w) em cada época\n",
    "    for t in range(epochs):\n",
    "        ei_sum = np.zeros(X.shape[1])\n",
    "        for i in range(n):\n",
    "            ei = y[i] - sigmoid(np.dot(w.T, X[i]))\n",
    "            ei_sum += np.dot(ei, X[i])\n",
    "        w = w + learning_rate * (ei_sum/n)\n",
    "        # w = w + learning_rate * np.mean(np.dot(e, X))\n",
    "    return w\n",
    "\n",
    "def log_reg_GD_predict(train_set, test_set, learning_rate, epochs):\n",
    "    features = np.arange(30)\n",
    "    output = 30\n",
    "\n",
    "    # pega colunas de treino\n",
    "    train_set = Set(train_set, features, output)\n",
    "    X_train = train_set.get_X(normal_fun=stats.zscore)\n",
    "    y_train = train_set.get_y()\n",
    "\n",
    "    # treina modelo\n",
    "    w_train = GD(X_train, y_train, learning_rate, epochs)\n",
    "\n",
    "    # pega colunas de teste\n",
    "    test_set = Set(test_set, features, output)\n",
    "    X_test = test_set.get_X(normal_fun=stats.zscore)\n",
    "    y_test = test_set.get_y()\n",
    "\n",
    "    # testa modelo\n",
    "    y_pred = sigmoid(np.dot(w_train, X_test.T))\n",
    "    y_pred = np.around(y_pred)\n",
    "\n",
    "    return (y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GDA(x, y):\n",
    "    pCk_, mu_k_, sigma_k_ = [], [], []\n",
    "\n",
    "    N = y.shape[0]\n",
    "    for k in np.unique(y):\n",
    "        # calcula p(Ck)\n",
    "        n = y[y==k].shape[0]\n",
    "        pCk = n/N\n",
    "        pCk_.append(pCk)\n",
    "\n",
    "        # calcula mu_k\n",
    "        xk = x[y==k]\n",
    "        mu_k = xk.mean()\n",
    "        mu_k_.append(mu_k)\n",
    "        \n",
    "        # calcula sigma_k\n",
    "        sigma_k = (xk - mu_k).T.dot(xk - mu_k) / (xk.shape[0] - 1)\n",
    "        sigma_k_.append(sigma_k)\n",
    "\n",
    "    return (pCk_, mu_k_, sigma_k_)\n",
    "\n",
    "def GDA_predict(train_set, test_set):\n",
    "    features = np.arange(30)\n",
    "    output = 30\n",
    "\n",
    "    # pega colunas de treino\n",
    "    train_set = Set(train_set, features, output)\n",
    "    x_train = train_set.get_x()\n",
    "    y_train = train_set.get_y()\n",
    "\n",
    "    # treina modelo\n",
    "    pC, mu, sigma = GDA(x_train, y_train)\n",
    "    \n",
    "    # pega colunas de teste\n",
    "    test_set = Set(test_set, features, output)\n",
    "    x_test = test_set.get_x()\n",
    "    y_test = test_set.get_y()\n",
    "\n",
    "    y_pred = []\n",
    "    for i, y in enumerate(y_test):\n",
    "        y_probabilities = []\n",
    "        # para cada classe, verifica as probabilidades\n",
    "        for k, classification in enumerate(np.unique(y_test)):\n",
    "            eq1 = np.log(pC[k])\n",
    "            eq2 = (-0.5 * np.log(np.linalg.det(sigma[k])))\n",
    "            aux = x_test[i] - mu[k]\n",
    "            eq3 = (-0.5 * aux.T) @ (np.linalg.pinv(sigma[k]) @ aux)\n",
    "            \n",
    "            prob = eq1 + eq2 + eq3\n",
    "            y_probabilities.append(prob)\n",
    "\n",
    "        # escolhe a mais provável\n",
    "        y_pred.append(np.argmax(y_probabilities))\n",
    "        # print(y_probabilities)\n",
    "\n",
    "    return (y_test, np.array(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(train, test):\n",
    "    features_i = np.arange(30)\n",
    "    output_i = 30\n",
    "    train = Set(train, features_i, output_i)\n",
    "    test = Set(test, features_i, output_i)\n",
    "\n",
    "    x, y, x_test, y_test = train.get_x_apply(stats.zscore), train.get_y(), test.get_x_apply(stats.zscore), test.get_y()\n",
    "\n",
    "    # treina o modelo\n",
    "    classes = np.unique(np.array(y, dtype='int64'))\n",
    "    pC, mu, sigma = [], [], []\n",
    "    for k in classes:\n",
    "        pC.append(y[y==k].shape[0] / y.shape[0])\n",
    "        mu.append(x[y==k].mean(axis=0))\n",
    "        sigma.append(x[y==k].std(axis=0))\n",
    "\n",
    "    # calcula probabilidades\n",
    "    rows, D = range(x_test.shape[0]), x_test.shape[1]\n",
    "    y_pred = []\n",
    "\n",
    "    # para cada xi dentro do x de teste\n",
    "    for i in rows:\n",
    "        y_probabilities = []\n",
    "\n",
    "        # calcula probabilidades das classes\n",
    "        for k in classes:\n",
    "            eq1 = np.log(pC[k])\n",
    "            eq2 = -0.5 * np.sum(np.log(2 * np.pi * sigma[k]))\n",
    "            eq3 = -0.5 * np.sum((x_test[i] - mu[k])**2 / sigma[k])\n",
    "            prob = eq1 + eq2 + eq3\n",
    "            y_probabilities.append(prob)\n",
    "\n",
    "        # escolhe a mais provável\n",
    "        y_pred.append(np.argmax(y_probabilities))\n",
    "\n",
    "    return (y_test, np.array(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Para cada modelo criado, reporte valor médio e desvio padrão das métricas de **acurácia**, **revocação**, **precisão** e **F1-score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_true_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y >= 1\n",
    "\n",
    "def is_false_positive(y, y_pred):\n",
    "    return y_pred >= 1 and y <= 0\n",
    "\n",
    "def is_true_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y <= 0\n",
    "\n",
    "def is_false_negative(y, y_pred):\n",
    "    return y_pred <= 0 and y >= 1\n",
    "\n",
    "def get_prediction_matrix(y, y_pred):\n",
    "    \"\"\" returns (tp, fp, tn, fn) \"\"\"\n",
    "\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for i, pred in enumerate(y_pred):\n",
    "        tp += 1 if is_true_positive(y[i], pred) else 0\n",
    "        fp += 1 if is_false_positive(y[i], pred) else 0\n",
    "        tn += 1 if is_true_negative(y[i], pred) else 0\n",
    "        fn += 1 if is_false_negative(y[i], pred) else 0\n",
    "    return (tp, fp, tn, fn)\n",
    "\n",
    "def accuracy(y, y_pred):\n",
    "    tp, fp, tn, fn = get_prediction_matrix(y, y_pred)\n",
    "    return (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "def precision(y, y_pred):\n",
    "    tp, fp, tn, fn = get_prediction_matrix(y, y_pred)\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(y, y_pred):\n",
    "    tp, fp, tn, fn = get_prediction_matrix(y, y_pred)\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "def f1_score(y, y_pred):\n",
    "    precision_ = precision(y, y_pred)\n",
    "    recall_ = recall(y, y_pred)\n",
    "    return 2 * (precision_ * recall_) / (precision_ + recall_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold cross validation com Regressão logística (GD)\n",
      "acurácia: 0.93668546 +/- 0.03071788\n",
      "revocação: 0.94632035 +/- 0.05628245\n",
      "precisão: 0.95434642 +/- 0.03264910\n",
      "f1-score: 0.94870336 +/- 0.02630920\n",
      "\n",
      "10-fold cross validation com Análise Discriminante Gaussiana\n",
      "acurácia: 0.95598371 +/- 0.03719696\n",
      "revocação: 0.96550712 +/- 0.05047300\n",
      "precisão: 0.96412776 +/- 0.04898371\n",
      "f1-score: 0.96310050 +/- 0.03161546\n",
      "\n",
      "10-fold cross validation com Naive Bayes Gaussiana\n",
      "acurácia: 0.92781955 +/- 0.03681396\n",
      "revocação: 0.91590736 +/- 0.06625456\n",
      "precisão: 0.97602470 +/- 0.02341703\n",
      "f1-score: 0.94305233 +/- 0.03128240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    {\n",
    "        'name': \"Regressão logística (GD)\",\n",
    "        'function': log_reg_GD_predict,\n",
    "        'args': [0.01, 100]\n",
    "    },\n",
    "    {\n",
    "        'name': \"Análise Discriminante Gaussiana\",\n",
    "        'function': GDA_predict\n",
    "    },\n",
    "    {\n",
    "        'name': \"Naive Bayes Gaussiana\",\n",
    "        'function': naive_bayes_predict\n",
    "    }\n",
    "]\n",
    "\n",
    "n_folds = len(folds)\n",
    "\n",
    "for model in models:\n",
    "    accuracy_, precision_, recall_, f1_score_ = np.zeros(n_folds), np.zeros(n_folds), np.zeros(n_folds), np.zeros(n_folds)\n",
    "\n",
    "    for i, train, test in k_fold_train_test(folds):\n",
    "        y_test, y_pred = [], []\n",
    "        if 'args' in model:\n",
    "            y_test, y_pred = model['function'](train, test, *model['args'])\n",
    "        else:\n",
    "            y_test, y_pred = model['function'](train, test)\n",
    "        \n",
    "        accuracy_[i] = (accuracy(y_test, y_pred))\n",
    "        precision_[i] = (precision(y_test, y_pred))\n",
    "        recall_[i] = (recall(y_test, y_pred))\n",
    "        f1_score_[i] = (f1_score(y_test, y_pred))\n",
    "\n",
    "    print(\"%i-fold cross validation com %s\" % (n_folds, model['name']))\n",
    "    print(\"acurácia: %.8f +/- %.8f\" % (accuracy_.mean(), accuracy_.std()))\n",
    "    print(\"revocação: %.8f +/- %.8f\" % (precision_.mean(), precision_.std()))\n",
    "    print(\"precisão: %.8f +/- %.8f\" % (recall_.mean(), recall_.std()))\n",
    "    print(\"f1-score: %.8f +/- %.8f\" % (f1_score_.mean(), f1_score_.std()))\n",
    "    print(\"\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "77ab0bf75426114283fafc7207ca0245f7de4738c2866fb9aad708a7843cc047"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
